{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 웹 스크레이핑을 위한 기본 지식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML의 기본 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "하위 디렉터리 또는 파일 htmltest이(가) 이미 있습니다.\n"
     ]
    }
   ],
   "source": [
    "! mkdir htmltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./htmltest/HTML_example.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./htmltest/HTML_example.html \n",
    "<!doctype html>\n",
    "<html>\n",
    " <head>\n",
    "  <meta charset=\"utf-8\">\n",
    "  <title>이것은 HTML 예제</title>\n",
    " </head>\n",
    " <body>\n",
    "  <h1>출간된 책 정보</h1>\n",
    "  <p id=\"book_title\">이해가 쏙쏙 되는 파이썬</p>\n",
    "  <p id=\"author\">홍길동</p>\n",
    "  <p id=\"publisher\">위키북스 출판사</p>\n",
    "  <p id=\"year\">2018</p>\n",
    " </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./htmltest/HTML_example2.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./htmltest/HTML_example2.html \n",
    "<!doctype html>\n",
    "<html>\n",
    " <head>\n",
    "  <meta charset=\"utf-8\">\n",
    "  <title>이것은 HTML 예제</title>\n",
    " </head>\n",
    " <body>\n",
    "  <h1>출간된 책 정보</h1>\n",
    "  <p>이해가 쏙쏙 되는 파이썬</p>\n",
    "  <p>홍길동</p>\n",
    "  <p>위키북스 출판사</p>\n",
    "  <p>2018</p>\n",
    " </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 페이지의 HTML 소스 갖고 오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "res = requests.get(\"https://www.google.co.kr\")\n",
    "res\n",
    "\n",
    "# 출력값\n",
    "# <Response [200]>\n",
    "# 올바르게 요청에 응답받는 경우에는 200번대 코드가 나온다.\n",
    "# 오류 발생시에는 보통 400, 500번대 코드를 반환하게 되는 것. 500번대는 좀 심각한 오류임.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"ko\"><head><meta content=\"text/html; charset=UTF-8\" http-equiv=\"Content-Type\"><meta content=\"/images/branding/googleg/1x/googleg_standard_color_128dp.png\" itemprop=\"image\"><title>Google</title><script nonce=\"yC2PThRMPrbDPvSF'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.text[0:300]\n",
    "# .text를 붙이면 해당하는 text문을 모두 불러올 수 있다.\n",
    "# 너무 길어서 [0:300]으로 범위 지정한 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"ko\"><head><meta content=\"text/html; charset=UTF-8\" http-equiv=\"Content-Type\"><meta content=\"/images/branding/googleg/1x/googleg_standard_color_128dp.png\" itemprop=\"image\"><title>Google</title><script nonce=\"+JtKn40rQ7tYI3vD'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "html = requests.get(\"https://www.google.co.kr\").text\n",
    "html[0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잘못된 url 입력하는 경우\n",
    "\n",
    "# import requests\n",
    "\n",
    "# html_error = requests.get(\"https/ww.google.go.kr\").text\n",
    "\n",
    "# 출력값\n",
    "# MissingSchema: Invalid URL 'https/ww.google.go.kr': No schema supplied. Perhaps you meant http://https/ww.google.go.kr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(requests.models.Response, str)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res), type(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML 소스코드를 분석하고 처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터 찾고 추출하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><div><span>\n",
       "<a href=\"http://www.naver.com\">naver</a>\n",
       "<a href=\"https://www.google.com\">google</a>\n",
       "<a href=\"http://www.daum.net/\">daum</a>\n",
       "</span></div></body></html>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 테스트용 html 코드\n",
    "html = \"\"\"\n",
    "<html><body><div><span>\n",
    "<a href=http://www.naver.com>naver</a>\n",
    "<a href=https://www.google.com>google</a>\n",
    "<a href=http://www.daum.net/>daum</a>\n",
    "</span></div></body></html>\n",
    "\"\"\"\n",
    "# html 코드를 BeaurifulSoup이 이해할 수 있는 형식으로 파싱이 필요한데 아래 코드로 형성한다.\n",
    "\n",
    "# BeautifulSoup를 이용해 HTML 소스를 파싱 \n",
    "soup = BeautifulSoup(html, 'lxml') # lxml은 모든 마크업랭귀지를 파싱해주는 옵션이다.\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup)\n",
    "# soup은 나오기는 html형식으로 출력되지만, 실제 type은 bs4.BeautifulSoup이다.\n",
    "# 이제 처리하기 편해진 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <div>\n",
      "   <span>\n",
      "    <a href=\"http://www.naver.com\">\n",
      "     naver\n",
      "    </a>\n",
      "    <a href=\"https://www.google.com\">\n",
      "     google\n",
      "    </a>\n",
      "    <a href=\"http://www.daum.net/\">\n",
      "     daum\n",
      "    </a>\n",
      "   </span>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://www.naver.com\">naver</a>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('a') # 'a'는 tagname\n",
    "# find를 쓰면 가장 첫번째 조건을 만족하는 내용만 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'naver'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('a').get_text()\n",
    "\n",
    "# 'a' tag 안에 있는 text문만 가지고 오고 싶은 경우에는 .get_text를 쓴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"http://www.naver.com\">naver</a>,\n",
       " <a href=\"https://www.google.com\">google</a>,\n",
       " <a href=\"http://www.daum.net/\">daum</a>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a')\n",
    "# beaurifulsoup에서 find_all 명령어를 사용할 때도 정규표현식 명령어에서 find를 쓸 때와 같이 리스트에 담아 반환해준다.\n",
    "\n",
    "# 주의할 점!!!\n",
    "# find_all로 나온 결과값은 list 내에 담기는 것의 의미를 이해하는 것이 중요하다!!!!!!\n",
    "# find는 값 자체를 하나 출력해주지만, find_all은 출력값이 하나일지라도 list 형식으로 돌려주므로\n",
    "# 그 값을 찾으려면 index[0]을 호출해야만 결과값을 볼 수 있는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**주의할 점!!!(find와 find_all의 차이점)**\n",
    "- find_all로 나온 결과값은 list 내에 담기는 것의 의미를 이해하는 것이 중요하다!!!!!!\n",
    "- find는 값 자체를 하나 출력해주지만, find_all은 출력값이 하나일지라도 list 형식으로 돌려주므로 그 값을 찾으려면 index[0]을 호출해야만 결과값을 볼 수 있는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver\n",
      "google\n",
      "daum\n"
     ]
    }
   ],
   "source": [
    "site_names = soup.find_all('a')\n",
    "for site_names in site_names:\n",
    "    print(site_names.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 테스트용 HTML 코드\n",
    "html2 = \"\"\"\n",
    "<html>\n",
    " <head>\n",
    "  <title>작품과 작가 모음</title>\n",
    " </head>\n",
    " <body>\n",
    "  <h1>책 정보</h1>\n",
    "  <p class=\"book_title\">토지</p>\n",
    "  <p class=\"author\">박경리</p>\n",
    "  \n",
    "  <p class=\"book_title\">태백산맥</p>\n",
    "  <p class=\"author\">조정래</p>\n",
    "\n",
    "  <p class=\"book_title\">감옥으로부터의 사색</p>\n",
    "  <p class=\"author\">신영복</p>\n",
    " </body>\n",
    "</html>\n",
    "\"\"\" \n",
    "# class를 잘 활용해야 한다. class 정보를 찾아가는 것이 훨씬 쉽다.\n",
    "# head 영역에서 design이나 구성을 정해놓고 나중에 class로 불러오기만 하면 한번에 적용되는 것.\n",
    "# 실제 파이썬 class변수 같은 느낌?\n",
    "\n",
    "soup2 = BeautifulSoup(html2, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>작품과 작가 모음</title>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<h1>책 정보</h1>\n",
       "<p class=\"book_title\">토지</p>\n",
       "<p class=\"author\">박경리</p>\n",
       "<p class=\"book_title\">태백산맥</p>\n",
       "<p class=\"author\">조정래</p>\n",
       "<p class=\"book_title\">감옥으로부터의 사색</p>\n",
       "<p class=\"author\">신영복</p>\n",
       "</body>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>책 정보</h1>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.body.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"book_title\">토지</p>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.body.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"book_title\">토지</p>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"book_title\">토지</p>,\n",
       " <p class=\"author\">박경리</p>,\n",
       " <p class=\"book_title\">태백산맥</p>,\n",
       " <p class=\"author\">조정래</p>,\n",
       " <p class=\"book_title\">감옥으로부터의 사색</p>,\n",
       " <p class=\"author\">신영복</p>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"book_title\">토지</p>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find('p', 'book_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"author\">박경리</p>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find('p', 'author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"book_title\">토지</p>,\n",
       " <p class=\"book_title\">태백산맥</p>,\n",
       " <p class=\"book_title\">감옥으로부터의 사색</p>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find_all('p', 'book_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"author\">박경리</p>,\n",
       " <p class=\"author\">조정래</p>,\n",
       " <p class=\"author\">신영복</p>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find_all('p', 'author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 토지 / 박경리 \n",
      " - 태백산맥 / 조정래 \n",
      " - 감옥으로부터의 사색 / 신영복 \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup2 = BeautifulSoup(html2, 'lxml')\n",
    "\n",
    "book_titles = soup2.find_all('p', 'book_title')\n",
    "authors = soup2.find_all('p', 'author')\n",
    "\n",
    "for book_title, author in zip(book_titles, authors):\n",
    "    print(' - {} / {} '.format(book_title.get_text(), author.get_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "? zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹 사이트에서 데이터 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순위 데이터를 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**웹사이트 순위**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "url = \"https://www.alexa.com/topsites/countries/KR\"\n",
    "\n",
    "html_website_ranking = requests.get(url).text\n",
    "soup_website_ranking = BeautifulSoup(html_website_ranking, 'lxml')\n",
    "\n",
    "# p 태그의 요소 안에서 a 태그의 요소를 찾음\n",
    "website_ranking = soup_website_ranking.select('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(website_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking = soup_website_ranking.find_all('div')\n",
    "len(website_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking = soup_website_ranking.find_all('div', 'tr site-listing')\n",
    "# html 검사로 찾은 영역 더블클릭해서 복사하는 식으로 하면 편함.\n",
    "len(website_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"tr site-listing\">\n",
       "<div class=\"td number\">1</div>\n",
       "<div class=\"td DescriptionCell\">\n",
       "<p class=\"\">\n",
       "<a href=\"/siteinfo/naver.com\">Naver.com</a>\n",
       "</p>\n",
       "<div class=\"description\">\n",
       " <span class=\"remainder\"></span>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"td right\"><p>14:11</p></div>\n",
       "<div class=\"td right\"><p>8.46</p></div>\n",
       "<div class=\"td right\"><p>9.00%</p></div>\n",
       "<div class=\"td right\"><p>75,421</p></div>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = website_ranking[0]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"td number\">1</div>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1 = tmp.find('div', 'td number')\n",
    "tmp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"/siteinfo/naver.com\">Naver.com</a>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp2 = tmp.find('a')\n",
    "tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = tmp1.get_text()\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Naver.com'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site = tmp2.get_text()\n",
    "site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/siteinfo/naver.com'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = tmp2['href']\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Top Sites in South Korea]\n",
      "--------------------------------------------------\n",
      "1위. Naver.com (/siteinfo/naver.com)\n",
      "2위. Youtube.com (/siteinfo/youtube.com)\n",
      "3위. Google.co.kr (/siteinfo/google.co.kr)\n",
      "4위. Google.com (/siteinfo/google.com)\n",
      "5위. Daum.net (/siteinfo/daum.net)\n",
      "6위. Tistory.com (/siteinfo/tistory.com)\n",
      "7위. Namu.wiki (/siteinfo/namu.wiki)\n",
      "8위. Facebook.com (/siteinfo/facebook.com)\n",
      "9위. Dcinside.com (/siteinfo/dcinside.com)\n",
      "10위. Wikipedia.org (/siteinfo/wikipedia.org)\n",
      "11위. Gmarket.co.kr (/siteinfo/gmarket.co.kr)\n",
      "12위. Twitter.com (/siteinfo/twitter.com)\n",
      "13위. Ruliweb.com (/siteinfo/ruliweb.com)\n",
      "14위. Blog.me (/siteinfo/blog.me)\n",
      "15위. Instagram.com (/siteinfo/instagram.com)\n",
      "16위. Twitch.tv (/siteinfo/twitch.tv)\n",
      "17위. 11st.co.kr (/siteinfo/11st.co.kr)\n",
      "18위. Auction.co.kr (/siteinfo/auction.co.kr)\n",
      "19위. Baidu.com (/siteinfo/baidu.com)\n",
      "20위. Inven.co.kr (/siteinfo/inven.co.kr)\n",
      "21위. Donga.com (/siteinfo/donga.com)\n",
      "22위. Qq.com (/siteinfo/qq.com)\n",
      "23위. Tmall.com (/siteinfo/tmall.com)\n",
      "24위. Amazon.com (/siteinfo/amazon.com)\n",
      "25위. Taobao.com (/siteinfo/taobao.com)\n",
      "26위. Marumaru.in (/siteinfo/marumaru.in)\n",
      "27위. Kakao.com (/siteinfo/kakao.com)\n",
      "28위. Torrenthaja.com (/siteinfo/torrenthaja.com)\n",
      "29위. Coupang.com (/siteinfo/coupang.com)\n",
      "30위. T.co (/siteinfo/t.co)\n",
      "31위. Afreecatv.com (/siteinfo/afreecatv.com)\n",
      "32위. Wasabisyrup.com (/siteinfo/wasabisyrup.com)\n",
      "33위. Nate.com (/siteinfo/nate.com)\n",
      "34위. Etoland.co.kr (/siteinfo/etoland.co.kr)\n",
      "35위. Netflix.com (/siteinfo/netflix.com)\n",
      "36위. Clien.net (/siteinfo/clien.net)\n",
      "37위. Nicovideo.jp (/siteinfo/nicovideo.jp)\n",
      "38위. Danawa.com (/siteinfo/danawa.com)\n",
      "39위. Interpark.com (/siteinfo/interpark.com)\n",
      "40위. Sohu.com (/siteinfo/sohu.com)\n",
      "41위. Ilbe.com (/siteinfo/ilbe.com)\n",
      "42위. Blogspot.com (/siteinfo/blogspot.com)\n",
      "43위. Microsoft.com (/siteinfo/microsoft.com)\n",
      "44위. Tumblr.com (/siteinfo/tumblr.com)\n",
      "45위. Apple.com (/siteinfo/apple.com)\n",
      "46위. Torrentmap.com (/siteinfo/torrentmap.com)\n",
      "47위. Nexon.com (/siteinfo/nexon.com)\n",
      "48위. Wemakeprice.com (/siteinfo/wemakeprice.com)\n",
      "49위. Aliexpress.com (/siteinfo/aliexpress.com)\n",
      "50위. Joins.com (/siteinfo/joins.com)\n"
     ]
    }
   ],
   "source": [
    "Rank = []\n",
    "Site = []\n",
    "Link = []\n",
    "\n",
    "print(\"[Top Sites in South Korea]\")\n",
    "print(\"-\"*50)\n",
    "for idx in range(len(website_ranking)):\n",
    "    tmp = website_ranking[idx]\n",
    "    tmp1 = tmp.find('div', 'td number')\n",
    "    tmp2 = tmp.find('a')\n",
    "    rank = tmp1.get_text()\n",
    "    site = tmp2.get_text()\n",
    "    link = tmp2['href']\n",
    "    \n",
    "    print('{}위. {} ({})'.format(rank, site, link))\n",
    "    \n",
    "    Rank.append(rank)\n",
    "    Site.append(site)\n",
    "    Link.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url2 = \"https://movie.naver.com/movie/sdb/rank/rmovie.nhn?sel=pnt&date=20181106\"\n",
    "\n",
    "html_website_ranking2 = requests.get(url2).text\n",
    "# print(html_website_ranking2)\n",
    "soup_website_ranking2 = BeautifulSoup(html_website_ranking2, 'lxml')\n",
    "\n",
    "# website_ranking2 = soup_website_ranking2.select('list_ranking')\n",
    "# website_ranking2 = soup_website_ranking2.select('tbody')\n",
    "# website_ranking2 = soup_website_ranking2.select('tr')\n",
    "# website_ranking2 = soup_website_ranking2.select('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# website_ranking2[0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(website_ranking2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking2 = soup_website_ranking2.find_all('list_ranking')\n",
    "len(website_ranking2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking2[0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking2 = soup_website_ranking2.find_all('tbody', 'tr')\n",
    "len(website_ranking2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking2[0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
